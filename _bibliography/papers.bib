---
---

% @string{aps = {American Physical Society,}}

@inproceedings{10.1145/3600160.3600167,
author = {Boshmaf, Yazan and Perera, Isuranga and Kumarasinghe, Udesh and Liyanage, Sajitha and Al Jawaheri, Husam},
title = {Dizzy: Large-Scale Crawling and Analysis of Onion Services},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600160.3600167},
doi = {10.1145/3600160.3600167},
abstract = {With nearly 2.5m users, onion services have become the prominent part of the darkweb. Over the last five years alone, the number of onion domains has increased 20x, reaching more than 700k unique domains in January 2022. As onion services host various types of illicit content, they have become a valuable resource for darkweb research and an integral part of e-crime investigation and threat intelligence. However, this content is largely un-indexed by today’s search engines and researchers have to rely on outdated or manually-collected datasets that are limited in scale, scope, or both. To tackle this problem, we built Dizzy: An open-source crawling and analysis system for onion services. Dizzy implements novel techniques to explore, update, check, and classify onion services at scale, without overwhelming the Tor network. We deployed Dizzy in April 2021 and used it to analyze more than 63.3m crawled onion webpages, focusing on domain operations, web content, cryptocurrency usage, and web graph. Our main findings show that onion services are unreliable due to their high churn rate, have a relatively small number of reachable domains that are often similar and illicit, enjoy a growing underground cryptocurrency economy, and have a graph that is relatively tightly-knit to, but topologically different from, the regular web’s graph.},
booktitle = {Proceedings of the 18th International Conference on Availability, Reliability and Security},
articleno = {9},
numpages = {11},
pdf = {https://dl.acm.org/doi/abs/10.1145/3600160.3600167},
selected = {true},
bibtex_show = {true},
preview = {dizzy.png},
location = {Benevento, Italy},
series = {ARES '23}
}

@inproceedings{heteroguard:icdmw:2022,
  author = {U. Kumarasinghe and M. Nabeel and K. De Zoysa and K. Gunawardana and C. Elvitigala},
  booktitle = {2022 IEEE International Conference on Data Mining Workshops (ICDMW)},
  title = {HeteroGuard: Defending Heterogeneous Graph Neural Networks against Adversarial Attacks},
  year = {2022},
  volume = {},
  issn = {},
  pages = {698-705},
  abstract = {Graph neural networks (GNNs) have achieved re-markable success in many application domains including drug discovery, program analysis, social networks, and cyber security. However, it has been shown that they are not robust against adversarial attacks. In the recent past, many adversarial attacks against homogeneous GNNs and defenses have been proposed. However, most of these attacks and defenses are ineffective on heterogeneous graphs as these algorithms optimize under the assumption that all edge and node types are of the same and further they introduce semantically incorrect edges to perturbed graphs. Here, we first develop, HetePR-BCD, a training time (i.e. poisoning) adversarial attack on heterogeneous graphs that outperforms the start of the art attacks proposed in the literature. Our experimental results on three benchmark heterogeneous graphs show that our attack, with a small perturbation budget of 15 &amp;#x0025;, degrades the performance up to 32 &amp;#x0025; (Fl score) compared to existing ones. It is concerning to mention that existing defenses are not robust against our attack. These defenses primarily modify the GNN&amp;#x0027;s neural message passing operators assuming that adversarial attacks tend to connect nodes with dissimilar features, but this assumption does not hold in heterogeneous graphs. We construct HeteroGuard, an effective defense against training time attacks including HetePR-BCD on heterogeneous models. HeteroGuard outperforms the existing defenses by 3&amp;#x2013;8 &amp;#x0025; on Fl score depending on the benchmark dataset.},
  doi = {10.1109/ICDMW58026.2022.00096},
  keywords = {graph neural networks;adversarial attacks;defenses;heterogeneous graphs},
  url = {https://ieeexplore.ieee.org/abstract/document/10031190},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA},
  month = {dec},
  pdf = {https://ieeexplore.ieee.org/document/10031190},
  selected = {true},
  bibtex_show = {true},
  preview = {heteroguard.png},
}

@misc{pdns_net:arxiv:2022,
  doi = {10.48550/ARXIV.2203.07969},
  url = {https://arxiv.org/abs/2203.07969},
  author = {Kumarasinghe, Udesh and Deniz, Fatih and Nabeel, Mohamed},
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {PDNS-Net: A Large Heterogeneous Graph Benchmark Dataset of Network Resolutions for Graph Learning},
  abstract = {In order to advance the state of the art in graph learning algorithms, it is necessary to construct large real-world datasets. While there are many benchmark datasets for homogeneous graphs, only a few of them are available for heterogeneous graphs. Furthermore, the latter graphs are small in size rendering them insufficient to understand how graph learning algorithms perform in terms of classification metrics and computational resource utilization. We introduce, PDNS-Net, the largest public heterogeneous graph dataset containing 447K nodes and 897K edges for the malicious domain classification task. Compared to the popular heterogeneous datasets IMDB and DBLP, PDNS-Net is 38 and 17 times bigger respectively. We provide a detailed analysis of PDNS-Net including the data collection methodology, heterogeneous graph construction, descriptive statistics and preliminary graph classification performance. The dataset is publicly available at this https URL. Our preliminary evaluation of both popular homogeneous and heterogeneous graph neural networks on PDNS-Net reveals that further research is required to improve the performance of these models on large heterogeneous graphs.},
  pdf = {https://arxiv.org/pdf/2203.07969},
  publisher = {arXiv},
  year = {2022},
  month = {mar},
  copyright = {Creative Commons Attribution 4.0 International},
  selected = {true},
  preview = {domain_ip_graph.jpg},
  bibtex_show = {true},
}
